{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_txt(pdf_file_path, txt_file_path):\n",
    "    with open(pdf_file_path, 'rb') as pdf_file:\n",
    "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "        \n",
    "        text = \"\"\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            text += page.extract_text().rstrip()\n",
    "\n",
    "    with open(txt_file_path, 'w', encoding='utf-8') as txt_file:\n",
    "        txt_file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_to_txt('/Users/Desktop/ACM CONFERENCE WORK/FINAL_LIST_DOCS/Oil_Natural_Gas_Corporation_Ltd_vs_Saw_Pipes_Ltd_on_17_April_2003.PDF', 'oil.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')  # Download the required NLTK data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_related_sentences(sentences, keyword):\n",
    "    related_sentences = []\n",
    "\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        if keyword.lower() in sentence.lower():\n",
    "            prev_sentence = sentences[i - 1].strip() if i > 0 else None\n",
    "            next_sentence = sentences[i + 1].strip() if i < len(sentences) - 1 else None\n",
    "            related_sentences.append({\n",
    "                \"Sentence\": sentence.strip(),\n",
    "                \"Previous\": prev_sentence,\n",
    "                \"Next\": next_sentence\n",
    "            })\n",
    "\n",
    "    return related_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/Desktop/ACM CONFERENCE WORK/codes/Oil Natural Gas Case/oil.txt', \"r\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Tokenize into sentences using nltk.sent_tokenize()\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "keyword = \"arbitral\"\n",
    "result = []\n",
    "\n",
    "related_sentences = find_related_sentences(sentences, keyword)\n",
    "result.extend(related_sentences)\n",
    "\n",
    "# Create a DataFrame with columns \"Sentence,\" \"Previous,\" and \"Next\"\n",
    "output_df = pd.DataFrame(result, columns=[\"Sentence\", \"Previous\", \"Next\"])\n",
    "\n",
    "# Save results to a new CSV\n",
    "output_df.to_csv(\"output_sentences_oil.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file read successfully with encoding: utf-8\n"
     ]
    }
   ],
   "source": [
    "encodings_to_try = ['utf-8', 'latin1', 'utf-16', 'ISO-8859-1']\n",
    "\n",
    "# Try reading the CSV file with different encodings\n",
    "for encoding in encodings_to_try:\n",
    "    try:\n",
    "        output_df = pd.read_csv(\"output_sentences_oil.csv\", encoding=encoding)\n",
    "        print(\"CSV file read successfully with encoding:\", encoding)\n",
    "        break  # Exit loop if successful\n",
    "    except UnicodeDecodeError:\n",
    "        print(\"Failed to read CSV file with encoding:\", encoding)\n",
    "        continue  # Try next encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Previous</th>\n",
       "      <th>Next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COURT'S JURISDICTION UNDER SECTION 34 OF THE A...</td>\n",
       "      <td>JUDGMENT:\\nJ U D G M E N T Shah, J.</td>\n",
       "      <td>In other words - whether the Court would have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In other words - whether the Court would have ...</td>\n",
       "      <td>COURT'S JURISDICTION UNDER SECTION 34 OF THE A...</td>\n",
       "      <td>Mr. Dushyant Dave, learned senior counsel appe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Application for setting aside arbitral award -...</td>\n",
       "      <td>For deciding this controversy, we would refer ...</td>\n",
       "      <td>(2) An arbitral award may be set aside by the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(2) An arbitral award may be set aside by the ...</td>\n",
       "      <td>Application for setting aside arbitral award -...</td>\n",
       "      <td>Explanation-Without prejudice to the generalit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For proper\\nadjudication of the question of ju...</td>\n",
       "      <td>However,\\nclause\\n(v) of sub-section 2(a) and ...</td>\n",
       "      <td>'ARBITRAL PROCEDURE' The ingredients of clause...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Hence, this part of the award passed by the\\na...</td>\n",
       "      <td>It is to be reiterated that it is the primary ...</td>\n",
       "      <td>CONCLUSIONS:-\\nIn the result, it is held that:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>(1) The Court can set aside the arbitral award...</td>\n",
       "      <td>CONCLUSIONS:-\\nIn the result, it is held that:...</td>\n",
       "      <td>(ii) if the arbitral procedure was not in acco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>(ii) if the arbitral procedure was not in acco...</td>\n",
       "      <td>(1) The Court can set aside the arbitral award...</td>\n",
       "      <td>However, exception for setting aside the award...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>However, exception for setting aside the award...</td>\n",
       "      <td>(ii) if the arbitral procedure was not in acco...</td>\n",
       "      <td>(c) If the award passed by the arbitral tribun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>(c) If the award passed by the arbitral tribun...</td>\n",
       "      <td>However, exception for setting aside the award...</td>\n",
       "      <td>(3) The award could be set aside if it is agai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Sentence  \\\n",
       "0   COURT'S JURISDICTION UNDER SECTION 34 OF THE A...   \n",
       "1   In other words - whether the Court would have ...   \n",
       "2   Application for setting aside arbitral award -...   \n",
       "3   (2) An arbitral award may be set aside by the ...   \n",
       "4   For proper\\nadjudication of the question of ju...   \n",
       "..                                                ...   \n",
       "81  Hence, this part of the award passed by the\\na...   \n",
       "82  (1) The Court can set aside the arbitral award...   \n",
       "83  (ii) if the arbitral procedure was not in acco...   \n",
       "84  However, exception for setting aside the award...   \n",
       "85  (c) If the award passed by the arbitral tribun...   \n",
       "\n",
       "                                             Previous  \\\n",
       "0                 JUDGMENT:\\nJ U D G M E N T Shah, J.   \n",
       "1   COURT'S JURISDICTION UNDER SECTION 34 OF THE A...   \n",
       "2   For deciding this controversy, we would refer ...   \n",
       "3   Application for setting aside arbitral award -...   \n",
       "4   However,\\nclause\\n(v) of sub-section 2(a) and ...   \n",
       "..                                                ...   \n",
       "81  It is to be reiterated that it is the primary ...   \n",
       "82  CONCLUSIONS:-\\nIn the result, it is held that:...   \n",
       "83  (1) The Court can set aside the arbitral award...   \n",
       "84  (ii) if the arbitral procedure was not in acco...   \n",
       "85  However, exception for setting aside the award...   \n",
       "\n",
       "                                                 Next  \n",
       "0   In other words - whether the Court would have ...  \n",
       "1   Mr. Dushyant Dave, learned senior counsel appe...  \n",
       "2   (2) An arbitral award may be set aside by the ...  \n",
       "3   Explanation-Without prejudice to the generalit...  \n",
       "4   'ARBITRAL PROCEDURE' The ingredients of clause...  \n",
       "..                                                ...  \n",
       "81  CONCLUSIONS:-\\nIn the result, it is held that:...  \n",
       "82  (ii) if the arbitral procedure was not in acco...  \n",
       "83  However, exception for setting aside the award...  \n",
       "84  (c) If the award passed by the arbitral tribun...  \n",
       "85  (3) The award could be set aside if it is agai...  \n",
       "\n",
       "[86 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_sen = pd.DataFrame(output_df['Previous'].astype(str) + ' ' + output_df['Sentence'].astype(str) + ' ' + output_df['Next'].astype(str), columns=['concat'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JUDGMENT:\n",
      "J U D G M E N T Shah, J. COURT'S JURISDICTION UNDER SECTION 34 OF THE ARBITRATION AND CONCILIATION\n",
      "ACT, 1966 Before dealing with the issues involved in this appeal, we would first decide the main\n",
      "point in controversy, namely - the ambit and scope of Court's jurisdiction in case where award\n",
      "passed by the Arbitral Tribunal is challenged under Section 34 of the Arbitration and Conciliation\n",
      "Act, 1996 (hereinafter referred to as \"the Act\") as the decision in this appeal would depend upon the\n",
      "said finding. In other words - whether the Court would have jurisdiction under Section 34 of the Act\n",
      "to set aside an award passed by the Arbitral Tribunal which is patently illegal or in contravention of\n",
      "the provisions of the Act or any other substantive law governing the parties or is against the terms of\n",
      "the contract?Oil & Natural Gas Corporation Ltd vs Saw Pipes Ltd on 17 April, 2003\n",
      "Indian Kanoon - http://indiankanoon.org/doc/919241/ 1Learned senior counsel Mr. Ashok Desai appearing for the appellant submitted that in case where\n",
      "there is clear violation of Sections 28 to 31 of the Act or the terms of the Contract between the\n",
      "parties, the said award can be and is required to be set aside by the Court while exercising\n",
      "jurisdiction under Section 34 of the Act.\n"
     ]
    }
   ],
   "source": [
    "print(concatenated_sen['concat'].iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_sen.to_csv('sentences_final_concatenated_oil.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_person_id_map(file_path):\n",
    "    person_id_map = {}\n",
    "\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        header = next(reader)\n",
    "        \n",
    "        for row in reader:\n",
    "            person_id_list = row[0]\n",
    "            person = person_id_list.strip()\n",
    "            person_id = row[1].strip()\n",
    "            person_id_map[person] = person_id\n",
    "\n",
    "    return person_id_map\n",
    "\n",
    "def create_location_id_map(file_path):\n",
    "    location_id_map = {}\n",
    "\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        header = next(reader)\n",
    "        \n",
    "        for row in reader:\n",
    "            location_id_list = row[0]\n",
    "            location = location_id_list.strip()\n",
    "            location_id = row[1].strip()\n",
    "            location_id_map[location] = location_id\n",
    "\n",
    "    return location_id_map\n",
    "\n",
    "def create_time_id_map(file_path):\n",
    "    time_id_map = {}\n",
    "\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        header = next(reader)\n",
    "        \n",
    "        for row in reader:\n",
    "            time_id_list = row[0].split(',')\n",
    "            time = time_id_list.strip()\n",
    "            time_id = row[1].strip()\n",
    "            time_id_map[time] = time_id\n",
    "\n",
    "    return time_id_map\n",
    "\n",
    "def create_event_id_map(file_path):\n",
    "    event_id_map = {}\n",
    "\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        header = next(reader)\n",
    "        \n",
    "        for row in reader:\n",
    "            event_id_list = row[0].split(',')\n",
    "            event = event_id_list.strip()\n",
    "            event_id = row[1].strip()\n",
    "            event_id_map[event] = event_id\n",
    "\n",
    "    return event_id_map\n",
    "\n",
    "def create_other_id_map(file_path):\n",
    "    other_id_map = {}\n",
    "\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        header = next(reader)\n",
    "        \n",
    "        for row in reader:\n",
    "            other_id_list = row[0].split(',')\n",
    "            other = other_id_list.strip()\n",
    "            other_id = row[1].strip()\n",
    "            other_id_map[other] = other_id\n",
    "\n",
    "    return other_id_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_person = '/Users/Desktop/ACM CONFERENCE WORK/Entities/Oil Natural Gas Case/person.csv'\n",
    "file_path_location = '/Users/Desktop/ACM CONFERENCE WORK/Entities/Oil Natural Gas Case/location.csv'\n",
    "file_path_time = '/Users/Desktop/ACM CONFERENCE WORK/Entities/Oil Natural Gas Case/time.csv'\n",
    "file_path_event = '/Users/Desktop/ACM CONFERENCE WORK/Entities/Oil Natural Gas Case/event.csv'\n",
    "file_path_other = '/Users/Desktop/ACM CONFERENCE WORK/Entities/Oil Natural Gas Case/activity.csv'\n",
    "person_id_map = create_person_id_map(file_path_person)\n",
    "location_id_map = create_location_id_map(file_path_location)\n",
    "time_id_map = create_location_id_map(file_path_time)\n",
    "event_id_map = create_location_id_map(file_path_event)\n",
    "other_id_map = create_location_id_map(file_path_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngrams(text, n=6):\n",
    "    words = text.split()\n",
    "    ngrams = []\n",
    "    for j in range(n, 0, -1):\n",
    "        for i in range(len(words)):\n",
    "            if i + j <= len(words):\n",
    "                ngrams.append(' '.join(words[i:i+j]))\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.replace(\"'s\", \"\")\n",
    "    text = text.replace(\".\", \"\")\n",
    "    text = text.replace(\";\", \"\")\n",
    "#     text = text.replace(\"-\", \"\")\n",
    "    text = text.replace(\"!\", \"\")\n",
    "    text = text.replace(\"?\", \"\")\n",
    "#     text = text.replace(\"/\", \"\")\n",
    "    text = text.replace(\"@\", \"\")\n",
    "    text = text.replace(\"#\", \"\")\n",
    "    text = text.replace(\",\", \"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_entities(text):\n",
    "    text = text.lower()\n",
    "    ngrams = generate_ngrams(text)\n",
    "    replaced_text = text\n",
    "\n",
    "    for ngram in ngrams:\n",
    "        original = ngram.lower()\n",
    "        \n",
    "        if original in person_id_map:\n",
    "            entity_id = person_id_map[original]\n",
    "            replaced_text = replaced_text.replace(ngram, entity_id)\n",
    "        else:\n",
    "            preprocessed_ngram = preprocess_text(ngram.lower())\n",
    "            if preprocessed_ngram in person_id_map:\n",
    "                entity_id = person_id_map[preprocessed_ngram]\n",
    "                replaced_text = replaced_text.replace(ngram, entity_id)\n",
    "            else:\n",
    "                if original in location_id_map:\n",
    "                    entity_id = location_id_map[original]\n",
    "                    replaced_text = replaced_text.replace(ngram, entity_id)\n",
    "                elif preprocessed_ngram in location_id_map:\n",
    "                    entity_id = location_id_map[preprocessed_ngram]\n",
    "                    replaced_text = replaced_text.replace(ngram, entity_id)\n",
    "                elif original in time_id_map:\n",
    "                    entity_id = time_id_map[original]\n",
    "                    replaced_text = replaced_text.replace(ngram, entity_id)\n",
    "                elif preprocessed_ngram in time_id_map:\n",
    "                    entity_id = time_id_map[preprocessed_ngram]\n",
    "                    replaced_text = replaced_text.replace(ngram, entity_id)\n",
    "                elif original in event_id_map:\n",
    "                    entity_id = event_id_map[original]\n",
    "                    replaced_text = replaced_text.replace(ngram, entity_id)\n",
    "                elif preprocessed_ngram in event_id_map:\n",
    "                    entity_id = event_id_map[preprocessed_ngram]\n",
    "                    replaced_text = replaced_text.replace(ngram, entity_id)\n",
    "                elif original in other_id_map:\n",
    "                    entity_id = other_id_map[original]\n",
    "                    replaced_text = replaced_text.replace(ngram, entity_id)\n",
    "                elif preprocessed_ngram in other_id_map:\n",
    "                    entity_id = other_id_map[preprocessed_ngram]\n",
    "                    replaced_text = replaced_text.replace(ngram, entity_id)\n",
    "                    \n",
    "    return replaced_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sentences_final_concatenated_oil.csv', 'r', encoding='latin-1') as csvfile:\n",
    "     reader = csv.reader(csvfile)\n",
    "     next(reader)\n",
    "     ref_sen = []\n",
    "     for row in reader:\n",
    "         sentence = row[0]\n",
    "         ref_sen.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sentences = []\n",
    "\n",
    "for sen in ref_sen:\n",
    "     s = replace_entities(sen)\n",
    "     final_sentences.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cleaned_sentences_oil.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Sentences'])\n",
    "#      for sen in final_sentences:\n",
    "    for sen in final_sentences:\n",
    "        writer.writerow([sen])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with the sentences\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "\n",
    "# Load the CSV files\n",
    "time_df = pd.read_csv(file_path_time)\n",
    "location_df = pd.read_csv(file_path_location)\n",
    "event_df = pd.read_csv(file_path_event)\n",
    "person_df = pd.read_csv(file_path_person)\n",
    "activity_df = pd.read_csv(file_path_other)\n",
    "\n",
    "location_ID = location_df['Id'].tolist()\n",
    "location_df = location_df['Location'].tolist()\n",
    "\n",
    "time_ID = time_df['Id'].tolist()\n",
    "time_df = time_df['Time'].tolist()\n",
    "\n",
    "# event_ID = event_df['ID'].tolist()\n",
    "# event_df = event_df['Event'].tolist()\n",
    "\n",
    "# person_ID = person_df['ID'].tolist()\n",
    "# person_df = person_df['Person'].tolist()\n",
    "\n",
    "# activity_ID = activity_df['ID'].tolist()\n",
    "# activity_df = activity_df['Others'].tolist()\n",
    "\n",
    "event_ID_map = dict(zip(event_df['Id'], event_df['Event']))\n",
    "person_ID_map = dict(zip(person_df['Id'], person_df['Person']))\n",
    "activity_ID_map = dict(zip(activity_df['Id'], activity_df['Activity']))\n",
    "\n",
    "matrix = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "with open('cleaned_sentences_oil.csv', 'r', encoding='latin-1') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        sentence = row[0]\n",
    "        sentences.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in sentences:\n",
    "    pattern = r'([PTLEA]\\d+)'\n",
    "    matches = re.findall(pattern, s)\n",
    "\n",
    "    persons = []\n",
    "    time = []\n",
    "    location = []\n",
    "    event = []\n",
    "    activity = []\n",
    "\n",
    "    for match in matches:\n",
    "        if match[0] == 'P':\n",
    "            persons.append(person_ID_map.get(match, 'Unknown Person'))\n",
    "        elif match[0] == 'L':\n",
    "             location.append(location_ID.index(match))\n",
    "        elif match[0] == 'E':\n",
    "            event.append(event_ID_map.get(match, 'Unknown Event'))\n",
    "        elif match[0] == 'A':\n",
    "            activity.append(activity_ID_map.get(match, 'Unknown Activity'))\n",
    "        elif match[0] == 'T':\n",
    "            time.append(time_ID.index(match))\n",
    "\n",
    "    if location and time:\n",
    "        for loc_index in location:\n",
    "            loc_key = location_df[loc_index]\n",
    "            for time_index in time:\n",
    "                time_key = time_df[time_index]\n",
    "                if time_key not in matrix:\n",
    "                    matrix[time_key] = {}\n",
    "                if loc_key not in matrix[time_key]:\n",
    "                    matrix[time_key][loc_key] = []\n",
    "                matrix[time_key][loc_key].extend([(entity, s) for entity in (persons + event + activity)])\n",
    "    elif location:\n",
    "        for loc_index in location:\n",
    "            loc_key = location_df[loc_index]\n",
    "            if loc_key not in matrix:\n",
    "                matrix[loc_key] = {}\n",
    "            if 'NULL' not in matrix:\n",
    "                matrix['NULL'] = {}\n",
    "            if loc_key not in matrix[\"NULL\"]:\n",
    "                matrix[\"NULL\"][loc_key] = []\n",
    "            matrix[\"NULL\"][loc_key].extend([(entity, s) for entity in (persons + event + activity)])\n",
    "    elif time:\n",
    "        for time_index in time:\n",
    "            time_key = time_df[time_index]\n",
    "            if time_key not in matrix:\n",
    "                matrix[time_key] = {}\n",
    "            if 'NULL' not in matrix[time_key]:\n",
    "                matrix[time_key]['NULL'] = []\n",
    "            matrix[time_key][\"NULL\"].extend([(entity, s) for entity in (persons + event + activity)])\n",
    "    else:\n",
    "        if 'NULL' not in matrix:\n",
    "            matrix['NULL'] = {}\n",
    "        if 'NULL' not in matrix['NULL']:\n",
    "            matrix['NULL']['NULL'] = []\n",
    "        matrix[\"NULL\"][\"NULL\"].extend([(entity, s) for entity in (persons + event + activity)])\n",
    "\n",
    "matrix_df = pd.DataFrame.from_dict(matrix, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_df.to_csv('matrix_with_sen_oil.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('matrix_with_sen_oil.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Unnamed: 0': 'Time'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    time = row['Time']\n",
    "    for location in df.columns:\n",
    "        if location == 'Time':\n",
    "            continue\n",
    "        # Convert the tuple to a string and add it as a node\n",
    "        G.add_node(f\"{time}, {location}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = set()\n",
    "\n",
    "# Update the final set with only the entities\n",
    "for value in pd.unique(df.drop(columns='Time').values.ravel()):\n",
    "    if pd.notnull(value):\n",
    "        value_list = ast.literal_eval(value)\n",
    "        entity_list = [entity for entity, sentence in value_list]\n",
    "        final.update(entity_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_nodes_from(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    time = row['Time']\n",
    "    for location in df.columns:\n",
    "        if location == 'Time':\n",
    "            continue\n",
    "        if pd.notnull(row[location]):\n",
    "            value_list = ast.literal_eval(row[location])\n",
    "            entity_list = [entity for entity, sentence in value_list]\n",
    "            for entity in entity_list:\n",
    "                if entity in final:\n",
    "                    # Convert the tuples to strings and add them as an edge\n",
    "                    G.add_edge(f\"{time}, {location}\", entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in list(G.nodes):\n",
    "    if not list(G.neighbors(node)):\n",
    "        G.remove_node(node)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node1 in G.nodes:\n",
    "    # Check if node1 can be split into a pair\n",
    "    if ', ' in node1:\n",
    "        parts1 = node1.split(\", \")\n",
    "        if len(parts1) == 2:  # Ensure it splits into exactly two parts\n",
    "            time1, location1 = parts1\n",
    "            for node2 in G.nodes:\n",
    "                # Check if node2 can be split into a pair\n",
    "                if ', ' in node2:\n",
    "                    parts2 = node2.split(\", \")\n",
    "                    if len(parts2) == 2:  # Ensure it splits into exactly two parts\n",
    "                        time2, location2 = parts2\n",
    "                        # Add edge if the time or location matches\n",
    "                        if time1 == time2 or location1 == location2:\n",
    "                            G.add_edge(node1, node2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_dict = dict(G.degree(G.nodes()))\n",
    "nx.set_node_attributes(G, degree_dict, 'degree')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the sentences for each node\n",
    "sentences_dict = {}\n",
    "\n",
    "# Create a dictionary to store the sentences for each edge i.e. between two nodes\n",
    "edge_sentences_dict = {}\n",
    "\n",
    "# Update the sentences_dict and edge_sentences_dict\n",
    "for index, row in df.iterrows():\n",
    "    time = row['Time']\n",
    "    for location in df.columns:\n",
    "        if location == 'Time':\n",
    "            continue\n",
    "        if pd.notnull(row[location]):\n",
    "            value_list = ast.literal_eval(row[location])\n",
    "            for entity, sentence in value_list:\n",
    "                if entity in final:\n",
    "                    # Add the sentence to the sentences_dict for the entity\n",
    "                    if entity not in sentences_dict:\n",
    "                        sentences_dict[entity] = set()\n",
    "                    sentences_dict[entity].add(sentence)\n",
    "\n",
    "                    # Add the sentence to the sentences_dict for the (time, location) node\n",
    "                    time_location_node = f\"{time}, {location}\"\n",
    "                    if time_location_node not in sentences_dict:\n",
    "                        sentences_dict[time_location_node] = set()\n",
    "                    sentences_dict[time_location_node].add(sentence)\n",
    "\n",
    "                    # Add the sentence to the edge_sentences_dict for the edge\n",
    "                    edge = (time_location_node, entity)\n",
    "                    if edge not in edge_sentences_dict:\n",
    "                        edge_sentences_dict[edge] = set()\n",
    "                    edge_sentences_dict[edge].add(sentence)\n",
    "\n",
    "# Convert the sets back to lists if needed\n",
    "for node, sentences in sentences_dict.items():\n",
    "    sentences_dict[node] = list(sentences)\n",
    "\n",
    "for edge, sentences in edge_sentences_dict.items():\n",
    "    edge_sentences_dict[edge] = list(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: node2vec in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.5.0)\n",
      "Requirement already satisfied: gensim<5.0.0,>=4.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from node2vec) (4.4.0)\n",
      "Requirement already satisfied: joblib<2.0.0,>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from node2vec) (1.4.2)\n",
      "Requirement already satisfied: networkx<4.0.0,>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from node2vec) (3.4.2)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.24.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from node2vec) (1.26.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from node2vec) (4.67.1)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gensim<5.0.0,>=4.3.0->node2vec) (1.15.1)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gensim<5.0.0,>=4.3.0->node2vec) (7.5.0)\n",
      "Requirement already satisfied: wrapt in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from smart_open>=1.8.1->gensim<5.0.0,>=4.3.0->node2vec) (2.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install node2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae37a9d2b114beeac8e2f540f739b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 4): 100%|██████████| 50/50 [00:00<00:00, 1759.95it/s]\n",
      "Generating walks (CPU: 2): 100%|██████████| 50/50 [00:00<00:00, 1748.56it/s]\n",
      "Generating walks (CPU: 3): 100%|██████████| 50/50 [00:00<00:00, 1732.08it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 50/50 [00:00<00:00, 1786.47it/s]\n"
     ]
    }
   ],
   "source": [
    "from node2vec import Node2Vec\n",
    "\n",
    "# Create a Node2Vec instance\n",
    "node2vec = Node2Vec(G, dimensions=64, walk_length=30, num_walks=200, workers=4)\n",
    "\n",
    "# Generate embeddings\n",
    "model = node2vec.fit(window=10, min_count=1, batch_words=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Get the node embeddings\n",
    "node_embeddings = {node: model.wv[node] for node in G.nodes}\n",
    "\n",
    "# Compute cosine similarity matrix\n",
    "similarity_matrix = cosine_similarity(list(node_embeddings.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Initialize DBSCAN\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=3)  # Adjust parameters as needed\n",
    "\n",
    "# Fit and predict clusters\n",
    "labels = dbscan.fit_predict(similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_colors = [\n",
    "    'rgb(31, 119, 180)',  # Blue\n",
    "    'rgb(255, 127, 14)',  # Orange\n",
    "    'rgb(44, 160, 44)',   # Green\n",
    "    'rgb(214, 39, 40)',   # Red\n",
    "    'rgb(148, 103, 189)', # Purple\n",
    "    'rgb(140, 86, 75)',   # Brown\n",
    "    'rgb(227, 119, 194)', # Pink\n",
    "    'rgb(127, 127, 127)', # Gray\n",
    "    'rgb(188, 189, 34)',  # Olive\n",
    "    'rgb(23, 190, 207)',  # Teal\n",
    "    'rgb(255, 187, 120)', # Peach\n",
    "    'rgb(214, 39, 40)',   # Maroon\n",
    "    'rgb(77, 175, 74)',   # Light Green\n",
    "    'rgb(152, 78, 163)',  # Plum\n",
    "    'rgb(255, 152, 150)'  # Salmon\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "none",
         "line": {
          "color": "gray",
          "width": 1
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          0.03822082793710216,
          0.8811172476321841,
          null,
          0.03822082793710216,
          -0.23025977505134698,
          null,
          0.03822082793710216,
          0.369759012841601,
          null,
          0.03822082793710216,
          -0.7790392245841928,
          null,
          0.03822082793710216,
          0.03822082793710216,
          null,
          0.03822082793710216,
          -0.2797980887753482,
          null,
          -0.2797980887753482,
          0.369759012841601,
          null,
          -0.2797980887753482,
          -0.7790392245841928,
          null,
          -0.2797980887753482,
          -0.2797980887753482,
          null
         ],
         "y": [
          0.08761764234807715,
          0.526809768202893,
          null,
          0.08761764234807715,
          1,
          null,
          0.08761764234807715,
          -0.7247028368458416,
          null,
          0.08761764234807715,
          -0.23344486678674148,
          null,
          0.08761764234807715,
          0.08761764234807715,
          null,
          0.08761764234807715,
          -0.6562797069183864,
          null,
          -0.6562797069183864,
          -0.7247028368458416,
          null,
          -0.6562797069183864,
          -0.23344486678674148,
          null,
          -0.6562797069183864,
          -0.6562797069183864,
          null
         ]
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "rgb(31, 119, 180)",
          "line": {
           "color": "black",
           "width": 2
          },
          "showscale": false,
          "size": 20
         },
         "mode": "markers+text",
         "text": [
          "nan, NULL",
          "p.a., NULL",
          "shortage of casing pipes",
          "delay in supply of goods",
          "commencement of arbitral proceedings",
          "oral hearings"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          0.03822082793710216,
          -0.2797980887753482,
          0.369759012841601,
          -0.7790392245841928,
          0.8811172476321841,
          -0.23025977505134698
         ],
         "y": [
          0.08761764234807715,
          -0.6562797069183864,
          -0.7247028368458416,
          -0.23344486678674148,
          0.526809768202893,
          1
         ]
        }
       ],
       "layout": {
        "height": 600,
        "hovermode": "closest",
        "margin": {
         "b": 20,
         "l": 5,
         "r": 5,
         "t": 40
        },
        "paper_bgcolor": "white",
        "plot_bgcolor": "white",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Cluster 1"
        },
        "width": 600,
        "xaxis": {
         "showgrid": false,
         "showticklabels": false,
         "zeroline": false
        },
        "yaxis": {
         "showgrid": false,
         "showticklabels": false,
         "zeroline": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "# Assuming 'G' is your graph and 'labels' is the list of labels\n",
    "# Renumber clusters from 1 to 7 if needed, otherwise ensure you have clusters numbered 1 to 7\n",
    "unique_labels = list(set(labels))\n",
    "label_mapping = {label: idx+1 for idx, label in enumerate(unique_labels)}\n",
    "\n",
    "def draw_subgraph_plotly(subgraph, cluster_id, cluster_color):\n",
    "    pos = nx.spring_layout(subgraph, seed=42)  # Fixed seed for reproducibility\n",
    "    \n",
    "    # Extract the node positions\n",
    "    x_nodes = [pos[node][0] for node in subgraph.nodes()]\n",
    "    y_nodes = [pos[node][1] for node in subgraph.nodes()]\n",
    "\n",
    "    # Extract the edges\n",
    "    edge_x = []\n",
    "    edge_y = []\n",
    "    for edge in subgraph.edges():\n",
    "        x0, y0 = pos[edge[0]]\n",
    "        x1, y1 = pos[edge[1]]\n",
    "        edge_x.extend([x0, x1, None])\n",
    "        edge_y.extend([y0, y1, None])\n",
    "\n",
    "    # Edge trace\n",
    "    edge_trace = go.Scatter(\n",
    "        x=edge_x, y=edge_y,\n",
    "        line=dict(width=1, color='gray'),\n",
    "        hoverinfo='none',\n",
    "        mode='lines')\n",
    "\n",
    "    # Node trace\n",
    "    node_trace = go.Scatter(\n",
    "        x=x_nodes, y=y_nodes,\n",
    "        mode='markers+text',\n",
    "        text=[f'{node}' for node in subgraph.nodes()],\n",
    "        textposition=\"top center\",\n",
    "        marker=dict(\n",
    "            showscale=False,\n",
    "            color=cluster_color,  # Assign the cluster color\n",
    "            size=20,\n",
    "            line=dict(width=2, color='black')\n",
    "        ),\n",
    "        hoverinfo='text'\n",
    "    )\n",
    "\n",
    "    # Create figure\n",
    "    fig = go.Figure(data=[edge_trace, node_trace],\n",
    "                    layout=go.Layout(\n",
    "                        title=f'Cluster {cluster_id}',\n",
    "                        showlegend=False,\n",
    "                        hovermode='closest',\n",
    "                        margin=dict(b=20, l=5, r=5, t=40),\n",
    "                        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                        height=600,\n",
    "                        width=600,\n",
    "                        paper_bgcolor='white',\n",
    "                        plot_bgcolor='white'\n",
    "                    ))\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "# Iterate over each cluster and draw the subgraph\n",
    "for original_cluster_id in set(labels):\n",
    "    cluster_id = label_mapping[original_cluster_id]\n",
    "    cluster_color = cluster_colors[cluster_id - 1]  # Assign a unique color to each cluster\n",
    "    cluster_nodes = [node for node, label in zip(G.nodes, labels) if label == original_cluster_id]\n",
    "    subgraph = G.subgraph(cluster_nodes)\n",
    "    draw_subgraph_plotly(subgraph, cluster_id, cluster_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize lists for nodes and links\n",
    "# nodes = []\n",
    "# links = []\n",
    "\n",
    "# # Add nodes to the list\n",
    "# for node, sentences in sentences_dict.items():\n",
    "#     nodes.append({\n",
    "#         \"id\": node,\n",
    "#         \"group\": 1,  # Update this as needed\n",
    "#         \"size\": len(sentences)  # The size could be based on the number of sentences\n",
    "#     })\n",
    "\n",
    "# # Add links to the list\n",
    "# for edge, sentences in edge_sentences_dict.items():\n",
    "#     source, target = edge\n",
    "#     links.append({\n",
    "#         \"source\": source,\n",
    "#         \"target\": target,\n",
    "#         \"value\": len(sentences)  # The value could be based on the number of sentences\n",
    "#     })\n",
    "\n",
    "# # Combine nodes and links into a single dictionary\n",
    "# graph_data = {\n",
    "#     \"nodes\": nodes,\n",
    "#     \"links\": links\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# os.environ['METIS_DLL'] = '/Users/.local/lib/libmetis.dylib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import metis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edgecuts, parts = metis.part_graph(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Create a mapping from nodes to integers\n",
    "node_to_int = {node: i for i, node in enumerate(G.nodes)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/networkx/readwrite/json_graph/node_link.py:142: FutureWarning:\n",
      "\n",
      "\n",
      "The default value will be `edges=\"edges\" in NetworkX 3.6.\n",
      "\n",
      "To make this warning go away, explicitly set the edges kwarg, e.g.:\n",
      "\n",
      "  nx.node_link_data(G, edges=\"links\") to preserve current behavior, or\n",
      "  nx.node_link_data(G, edges=\"edges\") for forward compatibility.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "degree_dict = dict(G.degree(G.nodes()))\n",
    "nx.set_node_attributes(G, degree_dict, 'degree')\n",
    "\n",
    "data = nx.node_link_data(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data = {\n",
    "    \"nodes\": [{\"name\": str(node), \"n\": degree_dict[node], \"grp\": int(labels[i]), \"id\": str(node)} for i, node in enumerate(G.nodes())],\n",
    "    \"links\": [{\"source\": str(link_data['source']), \"target\": str(link_data['target']), \"value\": 1} for link_data in data['links']]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = json.dumps(graph_data)\n",
    "with open('data_oil.json', 'w') as f:\n",
    "    f.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "\n",
    "# # Create a dictionary where keys are part numbers and values are lists of nodes\n",
    "# part_dict = defaultdict(list)\n",
    "# for node, part in enumerate(parts):\n",
    "#     part_dict[part].append(node)\n",
    "\n",
    "# # Print the number of parts\n",
    "# print(\"Number of parts:\", len(part_dict))\n",
    "\n",
    "# # Print the nodes in each part\n",
    "# for part, nodes in part_dict.items():\n",
    "#     print(\"Part\", part, \":\", nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have already created clusters using DBSCAN and have 'labels' and 'G' available\n",
    "\n",
    "# Initialize an empty dictionary to store sentences for each cluster\n",
    "cluster_sentences_dict = {}\n",
    "\n",
    "# Iterate over each cluster\n",
    "for original_cluster_id in set(labels):\n",
    "    cluster_id = label_mapping[original_cluster_id]\n",
    "    cluster_nodes = [node for node, label in zip(G.nodes, labels) if label == original_cluster_id]\n",
    "    \n",
    "    # Initialize a set to store sentences for this cluster\n",
    "    cluster_sentences = set()\n",
    "    \n",
    "    # Iterate over nodes in the cluster\n",
    "    for node in cluster_nodes:\n",
    "        # Assuming 'node' contains the relevant information (e.g., entity, time, location)\n",
    "        # Extract sentences associated with this node and add them to the cluster_sentences set\n",
    "        if node in sentences_dict:\n",
    "            cluster_sentences.update(sentences_dict[node])\n",
    "    \n",
    "    # Store the cluster_sentences set in the cluster_sentences_dict\n",
    "    cluster_sentences_dict[cluster_id] = cluster_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'commencement of arbitral proceedings': ['this power includes the power\\nto determine the admissibility, relevance, the materiality and weight of any evidence. sections 20, 21\\nand 22 deal with place of arbitration, E17 and language\\nrespectively. thereafter, sections 23, 24 and 25 deal with statements of claim and defence, hearings\\nand written proceedings and procedure to be followed in case of default of a party.'],\n",
       " 'nan, NULL': ['in response thereto, it was pointed out that it was not\\nthe case of learned counsel mr. setalwad on behalf of the claimants that \"these stipulations in the\\ncontract for deduction of liquidated damages was by way of penalty\". further, the arbitral tribunal\\nobserved that in view of the decisions rendered in fateh chand and maula bux cases, \"all that we\\nare required to consider is whether the respondents have established their case of actual loss in\\nmoney terms because of the delay in the supply of the casing pipes under the contract between the\\nparties\". finally, the arbitral tribunal held that as the appellant has failed to prove the loss suffered\\nbecause of E11 as set out in the contract between the parties, it is required to\\nrefund the amount deducted by way of liquidated damages from the specified amount payable to the\\nrespondent.',\n",
       "  \"as the award directing the appellant to refund the amount deducted is set aside, question of\\ngranting interest on the same would not arise. still however, to demonstrate that the award passed\\nby the arbitral tribunal is, on the face of it, erroneous with regard to grant of interest, we deal with\\nthe same.oil & natural gas corporation ltd vs saw pipes ltd on 17 april, 2003\\nindian kanoon - http://indiankanoon.org/doc/919241/ 30arbitral tribunal arrived at the conclusion that the appellant wrongfully withheld/deducted the\\naggregate amount of us $ 3,04,970.20 on account of E11 and amount of\\nrs.15,75,559/- on account of excise duty, sales tax, freight charges deducted as and by way of\\nliquidated damages from the amount payable by the respondent and thereafter arrived at the\\nconclusion that the said amount was deducted from undisputed invoice amount, therefore, the said\\nclaim of the respondent cannot be held to be 'disputed claim'. it is apparent that the claim of the contractor to recover the said amount was disputed mainly\\nbecause it was agreed term between the parties that in case of E11 appellant was\\nentitled to recover damages at the rate as specified in the agreement.\",\n",
       "  'thereafter, the arbitral tribunal considered various decisions of this court regarding\\nrecovery of liquidated damages and arrived at the conclusion that it was for the\\nappellant to establish that they had suffered any loss because of the breach\\ncommitted by the respondent in not supplying the goods within the prescribed time\\nlimit. the arbitral tribunal thereafter appreciated the evidence and arrived at the\\nconclusion that in view of the statement volunteered by mr. arumoy das, it was clear\\nthat E10 was only one of the other reasons which led to the\\nchange in the deployment plan and that it has failed to establish its case that it has\\nsuffered any loss in terms of money because of E11 under the\\ncontract. hence, the arbitral tribunal held that appellant has wrongfully withheld the\\nagreed amount of us $ 3,04,970.20 and rs.15,75,559/- on account of customs duty,\\nsales tax, freight charges deducted by way of liquidated damages.',\n",
       "  'at this stage, we would refer to section 24 which is as under:-\\n\"24. hearings and written proceedings- (1) unless otherwise agreed by the parties,\\nthe arbitral tribunal shall decide whether to hold E16 for the presentation of\\nevidence or for oral argument, or whether the proceedings shall be conducted on the\\nbasis of documents and other materials;\\nprovided that the arbitral tribunal shall hold E16, at an appropriate stage of\\nthe proceedings, on a request by a party, unless the parties have agreed that no oral\\nhearing shall be held. (2) the parties shall be given sufficient advance notice of any hearing and of any\\nmeeting of the arbitral tribunal for the purposes of inspection of documents, goods or\\nother property.',\n",
       "  'therefore, when parties have expressly agreed that recovery from the contractor for\\nbreach of the contract is pre-estimated genuine liquidated damages and is not by way\\nof penalty duly agreed by the parties, there was no justifiable reason for the arbitral\\ntribunal to arrive at a conclusion that still the purchaser should prove loss suffered by\\nit because of E11 further, in arbitration proceedings, the arbitral tribunal is required to decide the\\ndispute in accordance with the terms of the contract. the agreement between the\\nparties specifically provides that without prejudice to any other right or remedy if the\\ncontractor fails to deliver the stores within the stipulated time, appellant will be\\nentitled to recover from the contractor, as agreed, liquidated damages equivalent to\\n1% of the contract price of the whole unit per week for such delay.',\n",
       "  'in the words we have emphasized in maula bux decision, it is\\nclear that if loss in terms of money can be determined, the party claiming the compensation \\'must\\nprove\\' the loss suffered by him\".oil & natural gas corporation ltd vs saw pipes ltd on 17 april, 2003\\nindian kanoon - http://indiankanoon.org/doc/919241/ 27thereafter the arbitral tribunal referred to the evidence and the following statement made by the\\nwitness das:\\n\"the re-deployment plan was made keeping in mind several constraints including\\nE10.\" further, the arbitral tribunal came to the conclusion that under these circumstances, the shortage of\\ncasing pipes of 26\" diameter and 30\" diameter pipes was not the only reason which led to\\nredeployment of rig trident ii to platform b 121. the arbitral tribunal also appreciated the other\\nevidence and held that the attempt on the part of the ongc to show that production of gas on\\nplatform b 121 was delayed because of the late supply of goods by the claimant failed.',\n",
       "  'further, the arbitral tribunal\\nobserved that in view of the decisions rendered in fateh chand and maula bux cases, \"all that we\\nare required to consider is whether the respondents have established their case of actual loss in\\nmoney terms because of the delay in the supply of the casing pipes under the contract between the\\nparties\". finally, the arbitral tribunal held that as the appellant has failed to prove the loss suffered\\nbecause of E11 as set out in the contract between the parties, it is required to\\nrefund the amount deducted by way of liquidated damages from the specified amount payable to the\\nrespondent. it is apparent from the aforesaid reasoning recorded by the arbitral tribunal that it failed to consider\\nsections 73 and 74 of the indian contract act and the ratio laid down in fateh chand\\'s case (supra)\\nwherein it is specifically held that jurisdiction of the court to award compensation in case of breach\\nof contract is unqualified except as to the maximum stipulated; and compensation has to be\\nreasonable.',\n",
       "  'hearings and written proceedings- (1) unless otherwise agreed by the parties,\\nthe arbitral tribunal shall decide whether to hold E16 for the presentation of\\nevidence or for oral argument, or whether the proceedings shall be conducted on the\\nbasis of documents and other materials;\\nprovided that the arbitral tribunal shall hold E16, at an appropriate stage of\\nthe proceedings, on a request by a party, unless the parties have agreed that no oral\\nhearing shall be held. (2) the parties shall be given sufficient advance notice of any hearing and of any\\nmeeting of the arbitral tribunal for the purposes of inspection of documents, goods or\\nother property. (3) all statements, documents or other information supplied to, or applications made\\nto the arbitral tribunal by one party shall be communicated to the other party, and\\nany expert report or evidentiary document on which the arbitral tribunal may rely in\\nmaking its decision shall be communicated to the parties.\"',\n",
       "  'with\\nregard to other contention on the basis of customs duty also, the arbitral tribunal\\narrived at the conclusion that it would not justify the delay in the supply of goods. thereafter, the arbitral tribunal considered various decisions of this court regarding\\nrecovery of liquidated damages and arrived at the conclusion that it was for the\\nappellant to establish that they had suffered any loss because of the breach\\ncommitted by the respondent in not supplying the goods within the prescribed time\\nlimit. the arbitral tribunal thereafter appreciated the evidence and arrived at the\\nconclusion that in view of the statement volunteered by mr. arumoy das, it was clear\\nthat E10 was only one of the other reasons which led to the\\nchange in the deployment plan and that it has failed to establish its case that it has\\nsuffered any loss in terms of money because of E11 under the\\ncontract.',\n",
       "  'the arbitral tribunal after\\nconsidering the decisions rendered by this court in the cases of fateh chand, maula bux and\\nrampur distillery (supra) arrived at the conclusion that \"in view of these three decisions of the\\nsupreme court, it is clear that it was for the respondents to establish that they had suffered any loss\\nbecause of the breach committed by the claimant in the supply of goods under the contract between\\nthe parties after 14th november, 1996. in the words we have emphasized in maula bux decision, it is\\nclear that if loss in terms of money can be determined, the party claiming the compensation \\'must\\nprove\\' the loss suffered by him\".oil & natural gas corporation ltd vs saw pipes ltd on 17 april, 2003\\nindian kanoon - http://indiankanoon.org/doc/919241/ 27thereafter the arbitral tribunal referred to the evidence and the following statement made by the\\nwitness das:\\n\"the re-deployment plan was made keeping in mind several constraints including\\nE10.\" further, the arbitral tribunal came to the conclusion that under these circumstances, the shortage of\\ncasing pipes of 26\" diameter and 30\" diameter pipes was not the only reason which led to\\nredeployment of rig trident ii to platform b 121.',\n",
       "  '{re:\\nprovash chandra dalui and another v. biswanath banerjee and another [1989 supp\\n(1) scc 487]}. therefore, when parties have expressly agreed that recovery from the contractor for\\nbreach of the contract is pre-estimated genuine liquidated damages and is not by way\\nof penalty duly agreed by the parties, there was no justifiable reason for the arbitral\\ntribunal to arrive at a conclusion that still the purchaser should prove loss suffered by\\nit because of E11 further, in arbitration proceedings, the arbitral tribunal is required to decide the\\ndispute in accordance with the terms of the contract.',\n",
       "  'it is\\nundoubtedly true that the witness has stated that redeployment plan was made keeping in mind\\nseveral constraints including E10 arbitral tribunal, therefore, took into\\nconsideration the aforesaid statement volunteered by the witness that E10 was\\nonly one of the several reasons and not the only reason which led to change in deployment of plan or\\nredeployment of rigs trident-ii platform b-121. in our view, in such a contract, it would be difficult\\nto prove exact loss or damage which the parties suffer because of the breach thereof.',\n",
       "  \"finally, the arbitral tribunal held that as the appellant has failed to prove the loss suffered\\nbecause of E11 as set out in the contract between the parties, it is required to\\nrefund the amount deducted by way of liquidated damages from the specified amount payable to the\\nrespondent. it is apparent from the aforesaid reasoning recorded by the arbitral tribunal that it failed to consider\\nsections 73 and 74 of the indian contract act and the ratio laid down in fateh chand's case (supra)\\nwherein it is specifically held that jurisdiction of the court to award compensation in case of breach\\nof contract is unqualified except as to the maximum stipulated; and compensation has to be\\nreasonable. under section 73, when a contract has been broken, the party who suffers by such\\nbreach is entitled to receive compensation for any loss caused to him which the parties knew when\\nthey made the contract to be likely to result from the breach of it.\",\n",
       "  'this power includes the power\\nto determine the admissibility, relevance, the materiality and weight of any evidence. sections 20, 21\\nand 22 deal with place of arbitration, E17 and language\\nrespectively. thereafter, sections 23, 24 and 25 deal with statements of claim and defence, hearings\\nand written proceedings and procedure to be followed in case of default of a party.'],\n",
       " 'oral hearings': ['at this stage, we would refer to section 24 which is as under:-\\n\"24. hearings and written proceedings- (1) unless otherwise agreed by the parties,\\nthe arbitral tribunal shall decide whether to hold E16 for the presentation of\\nevidence or for oral argument, or whether the proceedings shall be conducted on the\\nbasis of documents and other materials;\\nprovided that the arbitral tribunal shall hold E16, at an appropriate stage of\\nthe proceedings, on a request by a party, unless the parties have agreed that no oral\\nhearing shall be held. (2) the parties shall be given sufficient advance notice of any hearing and of any\\nmeeting of the arbitral tribunal for the purposes of inspection of documents, goods or\\nother property.',\n",
       "  'hearings and written proceedings- (1) unless otherwise agreed by the parties,\\nthe arbitral tribunal shall decide whether to hold E16 for the presentation of\\nevidence or for oral argument, or whether the proceedings shall be conducted on the\\nbasis of documents and other materials;\\nprovided that the arbitral tribunal shall hold E16, at an appropriate stage of\\nthe proceedings, on a request by a party, unless the parties have agreed that no oral\\nhearing shall be held. (2) the parties shall be given sufficient advance notice of any hearing and of any\\nmeeting of the arbitral tribunal for the purposes of inspection of documents, goods or\\nother property. (3) all statements, documents or other information supplied to, or applications made\\nto the arbitral tribunal by one party shall be communicated to the other party, and\\nany expert report or evidentiary document on which the arbitral tribunal may rely in\\nmaking its decision shall be communicated to the parties.\"'],\n",
       " 'shortage of casing pipes': ['thereafter, the arbitral tribunal considered various decisions of this court regarding\\nrecovery of liquidated damages and arrived at the conclusion that it was for the\\nappellant to establish that they had suffered any loss because of the breach\\ncommitted by the respondent in not supplying the goods within the prescribed time\\nlimit. the arbitral tribunal thereafter appreciated the evidence and arrived at the\\nconclusion that in view of the statement volunteered by mr. arumoy das, it was clear\\nthat E10 was only one of the other reasons which led to the\\nchange in the deployment plan and that it has failed to establish its case that it has\\nsuffered any loss in terms of money because of E11 under the\\ncontract. hence, the arbitral tribunal held that appellant has wrongfully withheld the\\nagreed amount of us $ 3,04,970.20 and rs.15,75,559/- on account of customs duty,\\nsales tax, freight charges deducted by way of liquidated damages.',\n",
       "  'in the words we have emphasized in maula bux decision, it is\\nclear that if loss in terms of money can be determined, the party claiming the compensation \\'must\\nprove\\' the loss suffered by him\".oil & natural gas corporation ltd vs saw pipes ltd on 17 april, 2003\\nindian kanoon - http://indiankanoon.org/doc/919241/ 27thereafter the arbitral tribunal referred to the evidence and the following statement made by the\\nwitness das:\\n\"the re-deployment plan was made keeping in mind several constraints including\\nE10.\" further, the arbitral tribunal came to the conclusion that under these circumstances, the shortage of\\ncasing pipes of 26\" diameter and 30\" diameter pipes was not the only reason which led to\\nredeployment of rig trident ii to platform b 121. the arbitral tribunal also appreciated the other\\nevidence and held that the attempt on the part of the ongc to show that production of gas on\\nplatform b 121 was delayed because of the late supply of goods by the claimant failed.',\n",
       "  'the arbitral tribunal after\\nconsidering the decisions rendered by this court in the cases of fateh chand, maula bux and\\nrampur distillery (supra) arrived at the conclusion that \"in view of these three decisions of the\\nsupreme court, it is clear that it was for the respondents to establish that they had suffered any loss\\nbecause of the breach committed by the claimant in the supply of goods under the contract between\\nthe parties after 14th november, 1996. in the words we have emphasized in maula bux decision, it is\\nclear that if loss in terms of money can be determined, the party claiming the compensation \\'must\\nprove\\' the loss suffered by him\".oil & natural gas corporation ltd vs saw pipes ltd on 17 april, 2003\\nindian kanoon - http://indiankanoon.org/doc/919241/ 27thereafter the arbitral tribunal referred to the evidence and the following statement made by the\\nwitness das:\\n\"the re-deployment plan was made keeping in mind several constraints including\\nE10.\" further, the arbitral tribunal came to the conclusion that under these circumstances, the shortage of\\ncasing pipes of 26\" diameter and 30\" diameter pipes was not the only reason which led to\\nredeployment of rig trident ii to platform b 121.',\n",
       "  'with\\nregard to other contention on the basis of customs duty also, the arbitral tribunal\\narrived at the conclusion that it would not justify the delay in the supply of goods. thereafter, the arbitral tribunal considered various decisions of this court regarding\\nrecovery of liquidated damages and arrived at the conclusion that it was for the\\nappellant to establish that they had suffered any loss because of the breach\\ncommitted by the respondent in not supplying the goods within the prescribed time\\nlimit. the arbitral tribunal thereafter appreciated the evidence and arrived at the\\nconclusion that in view of the statement volunteered by mr. arumoy das, it was clear\\nthat E10 was only one of the other reasons which led to the\\nchange in the deployment plan and that it has failed to establish its case that it has\\nsuffered any loss in terms of money because of E11 under the\\ncontract.',\n",
       "  'the arbitral tribunal thereafter appreciated the evidence and arrived at the\\nconclusion that in view of the statement volunteered by mr. arumoy das, it was clear\\nthat E10 was only one of the other reasons which led to the\\nchange in the deployment plan and that it has failed to establish its case that it has\\nsuffered any loss in terms of money because of E11 under the\\ncontract. hence, the arbitral tribunal held that appellant has wrongfully withheld the\\nagreed amount of us $ 3,04,970.20 and rs.15,75,559/- on account of customs duty,\\nsales tax, freight charges deducted by way of liquidated damages. the arbitral\\ntribunal further held that the respondent was entitled to recover the said amount\\nwith interest at the rate of 12 per cent T17',\n",
       "  'it is\\nundoubtedly true that the witness has stated that redeployment plan was made keeping in mind\\nseveral constraints including E10 arbitral tribunal, therefore, took into\\nconsideration the aforesaid statement volunteered by the witness that E10 was\\nonly one of the several reasons and not the only reason which led to change in deployment of plan or\\nredeployment of rigs trident-ii platform b-121. in our view, in such a contract, it would be difficult\\nto prove exact loss or damage which the parties suffer because of the breach thereof.'],\n",
       " 'delay in supply of goods': ['in response thereto, it was pointed out that it was not\\nthe case of learned counsel mr. setalwad on behalf of the claimants that \"these stipulations in the\\ncontract for deduction of liquidated damages was by way of penalty\". further, the arbitral tribunal\\nobserved that in view of the decisions rendered in fateh chand and maula bux cases, \"all that we\\nare required to consider is whether the respondents have established their case of actual loss in\\nmoney terms because of the delay in the supply of the casing pipes under the contract between the\\nparties\". finally, the arbitral tribunal held that as the appellant has failed to prove the loss suffered\\nbecause of E11 as set out in the contract between the parties, it is required to\\nrefund the amount deducted by way of liquidated damages from the specified amount payable to the\\nrespondent.',\n",
       "  \"as the award directing the appellant to refund the amount deducted is set aside, question of\\ngranting interest on the same would not arise. still however, to demonstrate that the award passed\\nby the arbitral tribunal is, on the face of it, erroneous with regard to grant of interest, we deal with\\nthe same.oil & natural gas corporation ltd vs saw pipes ltd on 17 april, 2003\\nindian kanoon - http://indiankanoon.org/doc/919241/ 30arbitral tribunal arrived at the conclusion that the appellant wrongfully withheld/deducted the\\naggregate amount of us $ 3,04,970.20 on account of E11 and amount of\\nrs.15,75,559/- on account of excise duty, sales tax, freight charges deducted as and by way of\\nliquidated damages from the amount payable by the respondent and thereafter arrived at the\\nconclusion that the said amount was deducted from undisputed invoice amount, therefore, the said\\nclaim of the respondent cannot be held to be 'disputed claim'. it is apparent that the claim of the contractor to recover the said amount was disputed mainly\\nbecause it was agreed term between the parties that in case of E11 appellant was\\nentitled to recover damages at the rate as specified in the agreement.\",\n",
       "  'thereafter, the arbitral tribunal considered various decisions of this court regarding\\nrecovery of liquidated damages and arrived at the conclusion that it was for the\\nappellant to establish that they had suffered any loss because of the breach\\ncommitted by the respondent in not supplying the goods within the prescribed time\\nlimit. the arbitral tribunal thereafter appreciated the evidence and arrived at the\\nconclusion that in view of the statement volunteered by mr. arumoy das, it was clear\\nthat E10 was only one of the other reasons which led to the\\nchange in the deployment plan and that it has failed to establish its case that it has\\nsuffered any loss in terms of money because of E11 under the\\ncontract. hence, the arbitral tribunal held that appellant has wrongfully withheld the\\nagreed amount of us $ 3,04,970.20 and rs.15,75,559/- on account of customs duty,\\nsales tax, freight charges deducted by way of liquidated damages.',\n",
       "  'further, the arbitral tribunal\\nobserved that in view of the decisions rendered in fateh chand and maula bux cases, \"all that we\\nare required to consider is whether the respondents have established their case of actual loss in\\nmoney terms because of the delay in the supply of the casing pipes under the contract between the\\nparties\". finally, the arbitral tribunal held that as the appellant has failed to prove the loss suffered\\nbecause of E11 as set out in the contract between the parties, it is required to\\nrefund the amount deducted by way of liquidated damages from the specified amount payable to the\\nrespondent. it is apparent from the aforesaid reasoning recorded by the arbitral tribunal that it failed to consider\\nsections 73 and 74 of the indian contract act and the ratio laid down in fateh chand\\'s case (supra)\\nwherein it is specifically held that jurisdiction of the court to award compensation in case of breach\\nof contract is unqualified except as to the maximum stipulated; and compensation has to be\\nreasonable.',\n",
       "  'with\\nregard to other contention on the basis of customs duty also, the arbitral tribunal\\narrived at the conclusion that it would not justify the delay in the supply of goods. thereafter, the arbitral tribunal considered various decisions of this court regarding\\nrecovery of liquidated damages and arrived at the conclusion that it was for the\\nappellant to establish that they had suffered any loss because of the breach\\ncommitted by the respondent in not supplying the goods within the prescribed time\\nlimit. the arbitral tribunal thereafter appreciated the evidence and arrived at the\\nconclusion that in view of the statement volunteered by mr. arumoy das, it was clear\\nthat E10 was only one of the other reasons which led to the\\nchange in the deployment plan and that it has failed to establish its case that it has\\nsuffered any loss in terms of money because of E11 under the\\ncontract.',\n",
       "  'the arbitral tribunal thereafter appreciated the evidence and arrived at the\\nconclusion that in view of the statement volunteered by mr. arumoy das, it was clear\\nthat E10 was only one of the other reasons which led to the\\nchange in the deployment plan and that it has failed to establish its case that it has\\nsuffered any loss in terms of money because of E11 under the\\ncontract. hence, the arbitral tribunal held that appellant has wrongfully withheld the\\nagreed amount of us $ 3,04,970.20 and rs.15,75,559/- on account of customs duty,\\nsales tax, freight charges deducted by way of liquidated damages. the arbitral\\ntribunal further held that the respondent was entitled to recover the said amount\\nwith interest at the rate of 12 per cent T17',\n",
       "  '{re:\\nprovash chandra dalui and another v. biswanath banerjee and another [1989 supp\\n(1) scc 487]}. therefore, when parties have expressly agreed that recovery from the contractor for\\nbreach of the contract is pre-estimated genuine liquidated damages and is not by way\\nof penalty duly agreed by the parties, there was no justifiable reason for the arbitral\\ntribunal to arrive at a conclusion that still the purchaser should prove loss suffered by\\nit because of E11 further, in arbitration proceedings, the arbitral tribunal is required to decide the\\ndispute in accordance with the terms of the contract.',\n",
       "  \"finally, the arbitral tribunal held that as the appellant has failed to prove the loss suffered\\nbecause of E11 as set out in the contract between the parties, it is required to\\nrefund the amount deducted by way of liquidated damages from the specified amount payable to the\\nrespondent. it is apparent from the aforesaid reasoning recorded by the arbitral tribunal that it failed to consider\\nsections 73 and 74 of the indian contract act and the ratio laid down in fateh chand's case (supra)\\nwherein it is specifically held that jurisdiction of the court to award compensation in case of breach\\nof contract is unqualified except as to the maximum stipulated; and compensation has to be\\nreasonable. under section 73, when a contract has been broken, the party who suffers by such\\nbreach is entitled to receive compensation for any loss caused to him which the parties knew when\\nthey made the contract to be likely to result from the breach of it.\",\n",
       "  'therefore, when parties have expressly agreed that recovery from the contractor for\\nbreach of the contract is pre-estimated genuine liquidated damages and is not by way\\nof penalty duly agreed by the parties, there was no justifiable reason for the arbitral\\ntribunal to arrive at a conclusion that still the purchaser should prove loss suffered by\\nit because of E11 further, in arbitration proceedings, the arbitral tribunal is required to decide the\\ndispute in accordance with the terms of the contract. the agreement between the\\nparties specifically provides that without prejudice to any other right or remedy if the\\ncontractor fails to deliver the stores within the stipulated time, appellant will be\\nentitled to recover from the contractor, as agreed, liquidated damages equivalent to\\n1% of the contract price of the whole unit per week for such delay.'],\n",
       " 'p.a., NULL': ['the arbitral tribunal thereafter appreciated the evidence and arrived at the\\nconclusion that in view of the statement volunteered by mr. arumoy das, it was clear\\nthat E10 was only one of the other reasons which led to the\\nchange in the deployment plan and that it has failed to establish its case that it has\\nsuffered any loss in terms of money because of E11 under the\\ncontract. hence, the arbitral tribunal held that appellant has wrongfully withheld the\\nagreed amount of us $ 3,04,970.20 and rs.15,75,559/- on account of customs duty,\\nsales tax, freight charges deducted by way of liquidated damages. the arbitral\\ntribunal further held that the respondent was entitled to recover the said amount\\nwith interest at the rate of 12 per cent T17']}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output.txt\", \"w\") as f:\n",
    "    f.write(str(sentences_dict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
